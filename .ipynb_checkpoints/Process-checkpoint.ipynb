{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6094c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openstudio\n",
    "import os\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from os import listdir\n",
    "import plotly.express as px\n",
    "import sqlite3\n",
    "import timedelta\n",
    "print('here')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150f5234",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 37\n",
      "tsunami   ===========    n73 Connection Status - Power_and_Heat - December 29 Y1\n",
      "+++++++++++++\n",
      "E, [2023-06-21T16:50:35.708364 #93659] ERROR -- : Extra arguments passed to the run command. Please refer to the help documentation.\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 229\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mprint\u001b[39m(scenario \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m   ===========   \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m model \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m outage_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m outage_date \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Y1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m#Run simulation\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[43mrun_individual_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutage_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutage_date_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration_hours_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_individual_simulation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m#Open Results\u001b[39;00m\n\u001b[1;32m    231\u001b[0m outage_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(save_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(scenario) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name_individual_simulation \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_time\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 185\u001b[0m, in \u001b[0;36mrun_individual_simulation\u001b[0;34m(outage_type, model_name, beginning_date, beginning_h, duration, save_path, output_dir_name, name_individual_simulation)\u001b[0m\n\u001b[1;32m    182\u001b[0m run_osw(osw_path)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# print(sql_dir)\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Open the results, process them, export to CSV\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mexport_results_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_individual_simulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 140\u001b[0m, in \u001b[0;36mexport_results_to_csv\u001b[0;34m(sql_dir, simulation_name, save_path)\u001b[0m\n\u001b[1;32m    129\u001b[0m     variables \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElectricity:Facilit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaturalGas:Facility\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    131\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZone Mean Air Temperature\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZone Thermal Comfort Fanger Model PMV\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    135\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZone Thermal Comfort Fanger Model PPD\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m#     sql_dir = '/Users/cbianchi/Documents/GitHub/example_workflow/output_ERMA/Power_and_Heat_14_Hangar/run/'\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m#List of all the available variables\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     table_variables \u001b[38;5;241m=\u001b[39m \u001b[43mdf_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT * FROM ReportDataDictionary WHERE ReportingFrequency = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHourly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m#     print(table_variables)\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \n\u001b[1;32m    144\u001b[0m     \n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m#create empty dataframe\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     df_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mIndex(pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-01-01 01:00:00\u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-01-01 00:59:00\u001b[39m\u001b[38;5;124m'\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m60min\u001b[39m\u001b[38;5;124m'\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_time\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 117\u001b[0m, in \u001b[0;36mdf_query\u001b[0;34m(query, sql_dir)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdf_query\u001b[39m(query, sql_dir):\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''opens sql, makes query (native sql), closes sql and returns df'''\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43msqlite3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meplusout.sql\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(query, conn)\n\u001b[1;32m    119\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "def create_osw(folder_path, outage_type, model_name, beginning_date, beginning_hour, duration, name_individual_simulation, output_dir_name):\n",
    "#     outage_type = 'Power_and_Heat'\n",
    "#     model_name = '14_Hangar'\n",
    "    \n",
    "#     folder_path = '/Users/cbianchi/Documents/GitHub/example_workflow/'\n",
    "    measures_path = folder_path + 'measures'\n",
    "    \n",
    "    \n",
    "    model_path = 'ERMA_Power_Outage/' + model_name + '/run/in.osm'\n",
    "    model_save_path = folder_path + output_dir_name + name_individual_simulation + '/' + name_individual_simulation\n",
    "    seed_file_name = name_individual_simulation + '.osm'\n",
    "    new_osw_path = model_save_path + '.osw'\n",
    "#     print(new_osw_path)\n",
    "    \n",
    "    \n",
    "\n",
    "    os_script = f\"\"\"\n",
    "    require 'openstudio'\n",
    "    require 'fileutils'\n",
    "    require 'pycall'\n",
    "    \n",
    "    # This is the path to the OpenStudio CLI\n",
    "    # If you call this script using the CLI,\n",
    "    # it will just return the path to the thing you called.\n",
    "    cli = OpenStudio::getOpenStudioCLI\n",
    "\n",
    "    # Setup a directory for all of the output\n",
    "    #FileUtils.rm_rf('{output_dir_name}')\n",
    "    #FileUtils.mkdir('{output_dir_name}')\n",
    "\n",
    "    # The osw defines the measures to run\n",
    "    osw = OpenStudio::WorkflowJSON.new('example.osw')\n",
    "    osw.addMeasurePath('{measures_path}')\n",
    "\n",
    "    # This example uses the built in OpenStudio example model, because it is convenient,\n",
    "    # but model files could be globbed from a directory and loaded.\n",
    "    model = OpenStudio::Model::exampleModel()\n",
    "\n",
    "    # For demonstration purposes, just give each model a unique name\n",
    "    # model_names = ['one', 'two', 'three']\n",
    "    list_models = ['14_Hangar', '15_Hangar', '20_Hangar', '576ESU copy', '614_Cutterman', '614_Cutterman_2', 'N2', 'N23', 'N73', 'N96_2020', 'R2 copy', 'T1 copy']\n",
    "    outage_types = ['Power_and_Heat', 'Heat_only']\n",
    "    outage_date = ['January 2', 'March 5']\n",
    "\n",
    "    list_models = ['14_Hangar']\n",
    "    outage_types = ['Power_and_Heat']\n",
    "    #\n",
    "    # Load model building by building\n",
    "    model = OpenStudio::Model::Model.load('{model_path}').get\n",
    "\n",
    "    model.save(OpenStudio::toPath('{model_save_path}'), true)\n",
    "    # Update the osw to point to the new model\n",
    "    osw.setSeedFile('{seed_file_name}')\n",
    "    \n",
    "    # Set measure arguments\n",
    "    measure = OpenStudio::MeasureStep.new('set_power_and_heat_off')\n",
    "    measure.setArgument('otg_date','{beginning_date}')\n",
    "    measure.setArgument('otg_hr','{beginning_hour}')\n",
    "    measure.setArgument('otg_len','{duration}')\n",
    "    measure.setArgument('outage_type','{outage_type}'.gsub('_', ' '))\n",
    "    measure_type = OpenStudio::MeasureType.new('ModelMeasure')\n",
    "\n",
    "    var_measure1 = OpenStudio::MeasureStep.new('AddOutputVariable')\n",
    "    var_measure1.setArgument('variable_name','Zone Mean Air Temperature')\n",
    "    var_measure1.setArgument('reporting_frequency','hourly')\n",
    "    var_measure1.setArgument('key_value','*')\n",
    "    measure_type = OpenStudio::MeasureType.new('ReportingMeasure')\n",
    "\n",
    "    var_measure2 = OpenStudio::MeasureStep.new('AddOutputVariable')\n",
    "    var_measure2.setArgument('variable_name','Zone Operative Temperature')\n",
    "    var_measure2.setArgument('reporting_frequency','hourly')\n",
    "    var_measure2.setArgument('key_value','*')\n",
    "    measure_type = OpenStudio::MeasureType.new('ReportingMeasure')\n",
    "    \n",
    "    var_measure3 = OpenStudio::MeasureStep.new('AddOutputVariable')\n",
    "    var_measure3.setArgument('variable_name','Zone Thermal Comfort Fanger Model PMV')\n",
    "    var_measure3.setArgument('reporting_frequency','hourly')\n",
    "    var_measure3.setArgument('key_value','*')\n",
    "    measure_type = OpenStudio::MeasureType.new('ReportingMeasure')\n",
    "    \n",
    "    var_measure4 = OpenStudio::MeasureStep.new('AddOutputVariable')\n",
    "    var_measure4.setArgument('variable_name','Zone Thermal Comfort Fanger Model PPD')\n",
    "    var_measure4.setArgument('reporting_frequency','hourly')\n",
    "    var_measure4.setArgument('key_value','*')\n",
    "    measure_type = OpenStudio::MeasureType.new('ReportingMeasure')\n",
    "    \n",
    "    \n",
    "    osw.setWorkflowSteps([measure, var_measure1, var_measure2,  var_measure3,  var_measure4])\n",
    "\n",
    "    # Save the osw to a unique location\n",
    "    osw.saveAs(OpenStudio::toPath('{new_osw_path}'))\n",
    "    \"\"\"\n",
    "    cmd = '/Users/cbianchi/Documents/GitHub/example_workflow/OpenStudio-3.6.1+bb9481519e-Darwin-arm64/bin/openstudio -e \"{}\"'.format(os_script)\n",
    "    s = os.popen(cmd).read()\n",
    "    \n",
    "    print('+++++++++++++')\n",
    "    print(os_script)\n",
    "\n",
    "#     print(s)\n",
    "\n",
    "#     meter_measure1 = OpenStudio::MeasureStep.new('AddMeter')\n",
    "#     meter_measure1.setArgument('meter_name','Electricity:Facility')\n",
    "#     meter_measure1.setArgument('reporting_frequency','hourly')\n",
    "#     measure_type = OpenStudio::MeasureType.new('ModelMeasure')\n",
    "\n",
    "#     meter_measure2 = OpenStudio::MeasureStep.new('AddMeter')\n",
    "#     meter_measure2.setArgument('meter_name','NaturalGas:Facility')\n",
    "#     meter_measure2.setArgument('reporting_frequency','hourly')\n",
    "#     measure_type = OpenStudio::MeasureType.new('ReportingMeasure')\n",
    "\n",
    "def run_osw(osw_path):\n",
    "    os.system('openstudio run -w ' + osw_path)\n",
    "    \n",
    "    \n",
    "\n",
    "def df_query(query, sql_dir):\n",
    "    '''opens sql, makes query (native sql), closes sql and returns df'''\n",
    "    conn = sqlite3.connect(sql_dir + 'eplusout.sql' )\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "def filter_tabular(df, filterquery):\n",
    "    '''search available tabulardata for any string, return dataframe'''\n",
    "    lines = df[df.apply(lambda row: row.astype(str).str.contains(filterquery).any(), axis=1)]\n",
    "    return lines\n",
    "\n",
    "def export_results_to_csv(sql_dir, simulation_name, save_path):\n",
    "\n",
    "    variables = ['Electricity:Facilit',\n",
    "     'NaturalGas:Facility',\n",
    "     'Zone Mean Air Temperature',\n",
    "     'Zone Thermal Comfort ASHRAE 55 Adaptive Model Running Average Outdoor Air Temperature',\n",
    "     'Zone Operative Temperature',\n",
    "     'Zone Thermal Comfort Fanger Model PMV',\n",
    "     'Zone Thermal Comfort Fanger Model PPD']\n",
    "\n",
    "#     sql_dir = '/Users/cbianchi/Documents/GitHub/example_workflow/output_ERMA/Power_and_Heat_14_Hangar/run/'\n",
    "\n",
    "    #List of all the available variables\n",
    "    table_variables = df_query(\"SELECT * FROM ReportDataDictionary WHERE ReportingFrequency = 'Hourly'\", sql_dir)\n",
    "    \n",
    "#     print(table_variables)\n",
    "    \n",
    "    \n",
    "    #create empty dataframe\n",
    "    \n",
    "    df_final = pd.DataFrame(index=pd.Index(pd.date_range(start='2021-01-01 01:00:00', end='2022-01-01 00:59:00', freq='60min'), name='date_time'))\n",
    "#     df_final.index = \n",
    "    #Pinpoint individual variable and add it to the results DF\n",
    "    for var in variables:\n",
    "        var_names = filter_tabular(table_variables, var)['KeyValue'].values\n",
    "        indexes = filter_tabular(table_variables, var)['ReportDataDictionaryIndex'].values\n",
    "#         print(indexes)\n",
    "        for i in range(0,len(indexes)):\n",
    "    #         print(val)\n",
    "            column = df_query('SELECT \"Value\",\"ReportDataDictionaryIndex\",\"TimeIndex\" FROM \"ReportData\" WHERE \"ReportDataDictionaryIndex\"='+ str(indexes[i]), sql_dir)\n",
    "#             print(column)\n",
    "#             column['Value']\n",
    "            try:\n",
    "                name = var + '-' + var_names[i]\n",
    "            except TypeError:\n",
    "                name = var\n",
    "            df_final[name] = column['Value'].to_list()\n",
    "            \n",
    "#     print(df_final)\n",
    "    df_final.to_csv(save_path + simulation_name + '.csv')    \n",
    "    \n",
    "    \n",
    "def run_individual_simulation(outage_type, model_name, beginning_date,beginning_h, duration, save_path, output_dir_name, name_individual_simulation):\n",
    "    folder_path = '/Users/cbianchi/Documents/GitHub/example_workflow/'\n",
    "    # output_dir_name = 'output_ERMA/'\n",
    "    # save_path = 'results_CSVs/'\n",
    "    \n",
    "    osw_path = folder_path + output_dir_name + name_individual_simulation + '/' + name_individual_simulation + '.osw'\n",
    "    sql_dir = folder_path + output_dir_name + name_individual_simulation + '/run/'\n",
    "\n",
    "\n",
    "    #Start with creating the OSW in the right folder\n",
    "    create_osw(folder_path, outage_type, model_name, beginning_date, str(beginning_h), str(duration), name_individual_simulation, output_dir_name)\n",
    "\n",
    "    # Run the OS Simulation\n",
    "    run_osw(osw_path)\n",
    "    # print(sql_dir)\n",
    "    # Open the results, process them, export to CSV\n",
    "    export_results_to_csv(sql_dir, name_individual_simulation, save_path)\n",
    "    \n",
    "    \n",
    "#=========================================\n",
    "#Workflow individual simulation\n",
    "#=========================================  \n",
    "\n",
    "outage_list = pd.read_csv('outage_list.csv')\n",
    "save_path = 'results_CSVs/'\n",
    "output_dir_name = 'ERMA_simulations/'\n",
    "\n",
    "monitored_quantity = 'PMV'\n",
    "\n",
    "\n",
    "for i in range(0, len(outage_list))[37:]:\n",
    "    \n",
    "    print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ ' + str(i))\n",
    "    model = outage_list[outage_list.index==i]['model'].values[0]\n",
    "    outage_type = outage_list[outage_list.index==i]['outage_type'].values[0]\n",
    "    outage_date = outage_list[outage_list.index==i]['outage_date'].values[0]\n",
    "    duration_hours = outage_list[outage_list.index==i]['duration_hours'].values[0]\n",
    "    start_time = outage_list[outage_list.index==i]['start time'].values[0]\n",
    "    scenario = outage_list[outage_list.index==i]['scenario'].values[0]\n",
    "    event = outage_list[outage_list.index==i]['event'].values[0]\n",
    "    \n",
    "\n",
    "    #Reformat sart_time\n",
    "    start_time = pd.to_datetime(start_time).round(\"H\").hour\n",
    "    \n",
    "    # check if we are across 2 years\n",
    "    start_date = pd.to_datetime(outage_date + '2021', format='%B %d%Y') + pd.Timedelta(hours=start_time, minutes=0)\n",
    "    end_date = start_date + pd.Timedelta(hours=duration_hours, minutes=0)\n",
    "\n",
    "    if end_date > pd.to_datetime('2021-12-31 23:59:00'):\n",
    "        #Split Simulation in 2\n",
    "        start_date_1 = pd.to_datetime(start_date)\n",
    "        end_date_1 = pd.to_datetime('2021-12-31 23:59:00')\n",
    "        duration_hours_1 = timedelta.Timedelta(end_date_1 - start_date_1).total.hours\n",
    "        outage_date_1 = outage_date\n",
    "        start_time_1 = start_time\n",
    "        #Individual simulation name\n",
    "        name_individual_simulation = outage_type + '_' + model + '_' + outage_date.replace(' ', '_') + '_Y1'\n",
    "        print(scenario + '   ===========   ' + model + ' - ' + outage_type + ' - ' + outage_date + ' Y1')\n",
    "        #Run simulation\n",
    "        run_individual_simulation(outage_type, model, outage_date_1, start_time_1, duration_hours_1, save_path + str(scenario) + '/', output_dir_name + str(scenario) + '/', name_individual_simulation)\n",
    "        #Open Results\n",
    "        outage_df = pd.read_csv(save_path + str(scenario) + '/' + name_individual_simulation + '.csv', index_col = 'date_time', parse_dates = True)\n",
    "        outage_df = outage_df[(outage_df.index >= start_date_1) & (outage_df.index <= end_date_1)]\n",
    "        filtered_columns = list(filter(lambda x: any(substring in x for substring in [monitored_quantity]), outage_df.columns))\n",
    "        df_out_mean_y1 = outage_df[filtered_columns].mean(axis=1).to_frame()\n",
    "        \n",
    "        \n",
    "        #Second chunk\n",
    "        start_date_2 = pd.to_datetime('2021-01-01 00:00:00')\n",
    "        duration_hours_2 = duration_hours - duration_hours_1- 1\n",
    "        end_date_2 = start_date_2 + pd.Timedelta(hours=duration_hours_2, minutes=0)        \n",
    "        outage_date_2 = 'January 1'\n",
    "        start_time_2 = '0'\n",
    "        #Individual simulation name\n",
    "        name_individual_simulation = outage_type + '_' + model + '_' + outage_date.replace(' ', '_') + '_Y2'\n",
    "        print(scenario + '   ===========   ' + model + ' - ' + outage_type + ' - ' + outage_date + ' Y2')\n",
    "        #Run simulation\n",
    "        run_individual_simulation(outage_type, model, outage_date_2, start_time_2, duration_hours_2, save_path + str(scenario) + '/', output_dir_name + str(scenario) + '/', name_individual_simulation)\n",
    "        #Open Results\n",
    "        outage_df = pd.read_csv(save_path + str(scenario) + '/' + name_individual_simulation + '.csv', index_col = 'date_time', parse_dates = True)\n",
    "        outage_df = outage_df[(outage_df.index >= start_date_2) & (outage_df.index <= end_date_2)]\n",
    "        filtered_columns = list(filter(lambda x: any(substring in x for substring in [monitored_quantity]), outage_df.columns))\n",
    "        df_out_mean_y2 = outage_df[filtered_columns].mean(axis=1).to_frame()\n",
    "        \n",
    "        #Save\n",
    "        df_out_mean = df_out_mean_y1.append(df_out_mean_y2, ignore_index=False)\n",
    "\n",
    "    else:\n",
    "        #Individual simulation name\n",
    "        name_individual_simulation = outage_type + '_' + model + '_' + outage_date.replace(' ', '_')\n",
    "\n",
    "        print(scenario + '   ===========   ' + model + ' - ' + outage_type + ' - ' + outage_date)\n",
    "        #Run simulation\n",
    "        run_individual_simulation(outage_type, model, outage_date, start_time, duration_hours, save_path + str(scenario) + '/', output_dir_name + str(scenario) + '/', name_individual_simulation)\n",
    "\n",
    "        #Open Results\n",
    "        outage_df = pd.read_csv(save_path + str(scenario) + '/' + name_individual_simulation + '.csv', index_col = 'date_time', parse_dates = True)\n",
    "\n",
    "        outage_df = outage_df[(outage_df.index >= start_date) & (outage_df.index <= end_date)]\n",
    "        filtered_columns = list(filter(lambda x: any(substring in x for substring in [monitored_quantity]), outage_df.columns))\n",
    "        df_out_mean = outage_df[filtered_columns].mean(axis=1).to_frame()\n",
    "\n",
    "        \n",
    "    #Individual simulation name\n",
    "    name_individual_simulation = outage_type + '_' + model + '_' + outage_date.replace(' ', '_')\n",
    "    \n",
    "    df_out_mean = df_out_mean.rename(columns={df_out_mean.columns[0]: \"Average PMV\"})\n",
    "    df_out_mean.loc[df_out_mean['Average PMV'] <= -3, 'Habitability?'] = 'NH' \n",
    "    df_out_mean.loc[df_out_mean['Average PMV'] > -3, 'Habitability?'] = 'H' \n",
    "    df_out_mean.to_csv('outages_CSVs/' + str(scenario)+ '/' + name_individual_simulation + '.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10203438",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7219f89",
   "metadata": {},
   "source": [
    "# Downselect Outage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd51620",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('results_CSVs/Power_and_Heat_MWD_August_1.csv', index_col = 'date_time', parse_dates = True)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_models = ['15_Hangar']\n",
    "# outage_types = ['Power_and_Heat', 'Heat_only']\n",
    "# outage_types = ['Power_and_Heat']\n",
    "# outage_dates = ['January 2', 'May 5']\n",
    "# outage_dates = ['February 10']\n",
    "beginning_date = 'August 1'\n",
    "# beginning_hour = 3\n",
    "# duration = 25\n",
    "# if beginning_hour<10:\n",
    "#     hour_start = '0' + str(beginning_hour)\n",
    "# else:\n",
    "#     hour_start = str(beginning_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0738ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pd.to_datetime(beginning_date + '2021' + hour_start + ':00', format='%B %d%Y%H:M')\n",
    "start_date = pd.to_datetime(beginning_date + '2021', format='%B %d%Y') + pd.Timedelta(hours=beginning_hour-1, minutes=0)\n",
    "\n",
    "end_date = start_date + pd.Timedelta(hours=duration+2, minutes=0)\n",
    "outage_df = test[(test.index >= start_date) & (test.index <= end_date)]\n",
    "filtered_columns = list(filter(lambda x: any(substring in x for substring in ['PMV']), test.columns))\n",
    "outage_df[filtered_columns]\n",
    "# pd.to_datetime(beginning_date + ' 2021', format='%B %d %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ff0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3683ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01970ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bce8e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test.columns[]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
