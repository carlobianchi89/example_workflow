{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda0b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openstudio\n",
    "import os\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from os import listdir\n",
    "import plotly.express as px\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5961be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_osw(folder_path, outage_type, model_name, beginning_date, beginning_hour, duration, name_individual_simulation, output_dir_name):\n",
    "#     outage_type = 'Power_and_Heat'\n",
    "#     model_name = '14_Hangar'\n",
    "    \n",
    "#     folder_path = '/Users/cbianchi/Documents/GitHub/example_workflow/'\n",
    "    measures_path = folder_path + 'measures'\n",
    "    \n",
    "    \n",
    "    model_path = 'ERMA_Power_Outage/' + model_name + '/run/in.osm'\n",
    "    model_save_path = folder_path + output_dir_name + name_individual_simulation + '/' + name_individual_simulation\n",
    "    seed_file_name = name_individual_simulation + '.osm'\n",
    "    new_osw_path = model_save_path + '.osw'\n",
    "#     print(new_osw_path)\n",
    "    \n",
    "    os_script = f\"\"\"\n",
    "    require 'openstudio'\n",
    "    require 'fileutils'\n",
    "    require 'pycall'\n",
    "    \n",
    "    puts 'OOOOO'\n",
    "\n",
    "    # This is the path to the OpenStudio CLI\n",
    "    # If you call this script using the CLI,\n",
    "    # it will just return the path to the thing you called.\n",
    "    cli = OpenStudio::getOpenStudioCLI\n",
    "\n",
    "    # Setup a directory for all of the output\n",
    "    #FileUtils.rm_rf('{output_dir_name}')\n",
    "    #FileUtils.mkdir('{output_dir_name}')\n",
    "\n",
    "    # The osw defines the measures to run\n",
    "    osw = OpenStudio::WorkflowJSON.new('example.osw')\n",
    "    osw.addMeasurePath('{measures_path}')\n",
    "\n",
    "    # This example uses the built in OpenStudio example model, because it is convenient,\n",
    "    # but model files could be globbed from a directory and loaded.\n",
    "    model = OpenStudio::Model::exampleModel()\n",
    "\n",
    "    # For demonstration purposes, just give each model a unique name\n",
    "    # model_names = ['one', 'two', 'three']\n",
    "    list_models = ['14_Hangar', '15_Hangar', '20_Hangar', '576ESU copy', '614_Cutterman', '614_Cutterman_2', 'N2', 'N23', 'N73', 'N96_2020', 'R2 copy', 'T1 copy']\n",
    "    outage_types = ['Power_and_Heat', 'Heat_only']\n",
    "    outage_date = ['January 2', 'March 5']\n",
    "\n",
    "    list_models = ['14_Hangar']\n",
    "    outage_types = ['Power_and_Heat']\n",
    "    #\n",
    "    # Load model building by building\n",
    "    model = OpenStudio::Model::Model.load('{model_path}').get\n",
    "\n",
    "    model.save(OpenStudio::toPath('{model_save_path}'), true)\n",
    "    # Update the osw to point to the new model\n",
    "    osw.setSeedFile('{seed_file_name}')\n",
    "    \n",
    "    # Set measure arguments\n",
    "    measure = OpenStudio::MeasureStep.new('set_power_and_heat_off')\n",
    "    measure.setArgument('otg_date','{beginning_date}')\n",
    "    measure.setArgument('otg_hr','{beginning_hour}')\n",
    "    measure.setArgument('otg_len','{duration}')\n",
    "    measure.setArgument('outage_type','{outage_type}'.gsub('_', ' '))\n",
    "    measure_type = OpenStudio::MeasureType.new('ModelMeasure')\n",
    "\n",
    "    var_measure1 = OpenStudio::MeasureStep.new('AddOutputVariable')\n",
    "    var_measure1.setArgument('variable_name','Zone Mean Air Temperature')\n",
    "    var_measure1.setArgument('reporting_frequency','hourly')\n",
    "    var_measure1.setArgument('key_value','*')\n",
    "    measure_type = OpenStudio::MeasureType.new('ReportingMeasure')\n",
    "\n",
    "    osw.setWorkflowSteps([measure, var_measure1])\n",
    "\n",
    "    # Save the osw to a unique location\n",
    "    osw.saveAs(OpenStudio::toPath('{new_osw_path}'))\n",
    "    \"\"\"\n",
    "    cmd = '/Users/cbianchi/Documents/GitHub/example_workflow/OpenStudio-3.6.1+bb9481519e-Darwin-arm64/bin/openstudio -e \"{}\"'.format(os_script)\n",
    "    s = os.popen(cmd).read()\n",
    "#     print(s)\n",
    "\n",
    "#     meter_measure1 = OpenStudio::MeasureStep.new('AddMeter')\n",
    "#     meter_measure1.setArgument('meter_name','Electricity:Facility')\n",
    "#     meter_measure1.setArgument('reporting_frequency','hourly')\n",
    "#     measure_type = OpenStudio::MeasureType.new('ModelMeasure')\n",
    "\n",
    "#     meter_measure2 = OpenStudio::MeasureStep.new('AddMeter')\n",
    "#     meter_measure2.setArgument('meter_name','NaturalGas:Facility')\n",
    "#     meter_measure2.setArgument('reporting_frequency','hourly')\n",
    "#     measure_type = OpenStudio::MeasureType.new('ReportingMeasure')\n",
    "\n",
    "def run_osw(osw_path):\n",
    "    os.system('openstudio run -w ' + osw_path)\n",
    "    \n",
    "    \n",
    "\n",
    "def df_query(query, sql_dir):\n",
    "    '''opens sql, makes query (native sql), closes sql and returns df'''\n",
    "    conn = sqlite3.connect(sql_dir + 'eplusout.sql' )\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "def filter_tabular(df, filterquery):\n",
    "    '''search available tabulardata for any string, return dataframe'''\n",
    "    lines = df[df.apply(lambda row: row.astype(str).str.contains(filterquery).any(), axis=1)]\n",
    "    return lines\n",
    "\n",
    "def export_results_to_csv(sql_dir, simulation_name, save_path):\n",
    "\n",
    "    variables = ['Electricity:Facilit',\n",
    "     'NaturalGas:Facility',\n",
    "     'Zone Mean Air Temperature',\n",
    "     'Zone Thermal Comfort ASHRAE 55 Adaptive Model Running Average Outdoor Air Temperature',\n",
    "     'Zone Thermal Comfort Fanger Model PMV',\n",
    "     'Zone Thermal Comfort Fanger Model PPD']\n",
    "\n",
    "#     sql_dir = '/Users/cbianchi/Documents/GitHub/example_workflow/output_ERMA/Power_and_Heat_14_Hangar/run/'\n",
    "\n",
    "    #List of all the available variables\n",
    "    table_variables = df_query(\"SELECT * FROM ReportDataDictionary WHERE ReportingFrequency = 'Hourly'\", sql_dir)\n",
    "    \n",
    "#     print(table_variables)\n",
    "    \n",
    "    \n",
    "    #create empty dataframe\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final.index = pd.date_range(start='2021-01-01 00:00:00', end='2021-12-31 23:59:00', freq='60min')\n",
    "    #Pinpoint individual variable and add it to the results DF\n",
    "    for var in variables:\n",
    "        var_names = filter_tabular(table_variables, var)['KeyValue'].values\n",
    "        indexes = filter_tabular(table_variables, var)['ReportDataDictionaryIndex'].values\n",
    "#         print(indexes)\n",
    "        for i in range(0,len(indexes)):\n",
    "    #         print(val)\n",
    "            column = df_query('SELECT \"Value\",\"ReportDataDictionaryIndex\",\"TimeIndex\" FROM \"ReportData\" WHERE \"ReportDataDictionaryIndex\"='+ str(indexes[i]), sql_dir)\n",
    "#             print(column)\n",
    "#             column['Value']\n",
    "            try:\n",
    "                name = var + '-' + var_names[i]\n",
    "            except TypeError:\n",
    "                name = var\n",
    "            df_final[name] = column['Value'].to_list()\n",
    "            \n",
    "#     print(df_final)\n",
    "    df_final.to_csv(save_path + simulation_name + '.csv')    \n",
    "    \n",
    "    \n",
    "def run_individual_simulation(outage_type, model_name, beginning_date,beginning_h, duration ):\n",
    "    folder_path = '/Users/cbianchi/Documents/GitHub/example_workflow/'\n",
    "    output_dir_name = 'output_ERMA2/'\n",
    "    save_path = 'results_CSVs/'\n",
    "    name_individual_simulation = outage_type + '_' + model_name + '_' + beginning_date.replace(' ', '_')\n",
    "    osw_path = folder_path + output_dir_name + name_individual_simulation + '/' + name_individual_simulation + '.osw'\n",
    "    sql_dir = folder_path + output_dir_name + name_individual_simulation + '/run/'\n",
    "\n",
    "\n",
    "    #Start with creating the OSW in the right folder\n",
    "    create_osw(folder_path, outage_type, model_name, beginning_date, str(beginning_h), str(duration), name_individual_simulation, output_dir_name)\n",
    "    print('AAAAA')\n",
    "    # Run the OS Simulation\n",
    "    run_osw(osw_path)\n",
    "    # print(sql_dir)\n",
    "    # Open the results, process them, export to CSV\n",
    "    export_results_to_csv(sql_dir, name_individual_simulation, save_path)\n",
    "    \n",
    "    \n",
    "#=========================================\n",
    "#Workflow individual simulation\n",
    "#=========================================  \n",
    "    \n",
    "# '576ESU copy'\n",
    "# 'R2 copy'\n",
    "# 'T1 copy'\n",
    "\n",
    "list_models = ['14_Hangar', '15_Hangar', '20_Hangar', '614_Cutterman', '614_Cutterman_2', 'N2', 'N23', 'N73', 'N96_2020', 'R2_copy', 'T1_copy', '576ESU_copy']\n",
    "list_models = []\n",
    "outage_types = ['Power_and_Heat', 'Heat_only']\n",
    "outage_types = ['Power_and_Heat']\n",
    "outage_dates = ['January 2', 'May 5']\n",
    "outage_dates = ['May 5']\n",
    "\n",
    "for model_name in list_models:\n",
    "    for outage_type in outage_types:\n",
    "        for outage_date in outage_dates:\n",
    "            print('===========   ' + model_name + ' - ' + outage_type + ' - ' + outage_date)\n",
    "            run_individual_simulation(outage_type, model_name, outage_date, 2, 5)\n",
    "            \n",
    "            \n",
    "    \n",
    "# folder_path = '/Users/cbianchi/Documents/GitHub/example_workflow/'\n",
    "# output_dir_name = 'output_ERMA/'\n",
    "# save_path = 'results_CSVs/'\n",
    "\n",
    "\n",
    "    \n",
    "# outage_type = 'Power_and_Heat'\n",
    "# model_name = '14_Hangar'\n",
    "# beginning_date = 'June 1'\n",
    "# beginning_h = 5\n",
    "# duration = 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc383c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "osw_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdefc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_values_h(sql_dir, line_number):\n",
    "    sql_path = return_path(sql_dir)\n",
    "    conn = sqlite3.connect(sql_path)\n",
    "    c = conn.cursor()\n",
    "#     query = \"SELECT * FROM TabularDataWithStrings WHERE ReportName='AnnualBuildingUtilityPerformanceSummary' AND TableName='End Uses'\"\n",
    "    query = \"SELECT * FROM ReportMeterDataDictionary \"\n",
    "#     query = \"SELECT VariableValue FROM ReportMeterData WHERE ReportMeterDataDictionaryIndex= \" + str(line_number)\n",
    "    end_uses = pd.read_sql(query ,conn) #J\n",
    "    print(end_uses)\n",
    "    \n",
    "    electric_kWh = end_uses*2.7778e-7\n",
    "    return electric_kWh\n",
    "\n",
    "\n",
    "def return_path(sql_dir):\n",
    "    sql_file = 'eplusout.sql'\n",
    "    sql_path = os.path.join(sql_dir, sql_file)\n",
    "    write_dir = sql_dir\n",
    "    return sql_path\n",
    "\n",
    "\n",
    "\n",
    "def hourly_df(sql_dir, line_number):\n",
    "    \n",
    "#     try:\n",
    "#         df = pd.DataFrame()\n",
    "#         df['Modeled Data [kWh]'] = return_values_h(sql_dir, line_number)['VariableValue']\n",
    "#     #     df['Metered Data [kWh]'] = meter\n",
    "\n",
    "#         df.index = pd.date_range(start='2021-01-01 00:00:00', end='2021-12-31 23:59:00', freq='10min')\n",
    "#         df = df.resample('1h').sum()\n",
    "#     except:\n",
    "    df = pd.DataFrame()\n",
    "    df['Electricity [kWh]'] = return_values_h(sql_dir, line_number)['VariableValue']\n",
    "    df['NaturalGas [kWh]'] = return_values_h(sql_dir, 3421)['VariableValue']\n",
    "    \n",
    "#     df['Metered Data [kWh]'] = meter\n",
    "\n",
    "    df.index = pd.date_range(start='2021-01-01 00:00:00', end='2021-12-31 23:59:00', freq='60min')\n",
    "    df = df.resample('1h').sum()\n",
    "    \n",
    "#     df.rename(columns = {'Modeled Data [kWh]': bldg_name + ' [kWh]'}, inplace = True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "# meter = meters_N73_2020\n",
    "sql_dir = '/Users/cbianchi/Documents/GitHub/example_workflow/output_ERMA/Power_and_Heat_14_Hangar/run/'\n",
    "\n",
    "df = hourly_df(sql_dir, 9)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295df66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def df_query(query, sql_dir):\n",
    "    '''opens sql, makes query (native sql), closes sql and returns df'''\n",
    "    conn = sqlite3.connect(sql_dir + 'eplusout.sql' )\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "def filter_tabular(df, filterquery):\n",
    "    '''search available tabulardata for any string, return dataframe'''\n",
    "    lines = df[df.apply(lambda row: row.astype(str).str.contains(filterquery).any(), axis=1)]\n",
    "    return lines\n",
    "\n",
    "def export_results_to_csv(sql_dir, simulation_name, save_path)\n",
    "\n",
    "    variables = ['Electricity:Facilit',\n",
    "     'NaturalGas:Facility',\n",
    "     'Zone Mean Air Temperature',\n",
    "     'Zone Thermal Comfort ASHRAE 55 Adaptive Model Running Average Outdoor Air Temperature',\n",
    "     'Zone Thermal Comfort Fanger Model PMV',\n",
    "     'Zone Thermal Comfort Fanger Model PPD']\n",
    "\n",
    "#     sql_dir = '/Users/cbianchi/Documents/GitHub/example_workflow/output_ERMA/Power_and_Heat_14_Hangar/run/'\n",
    "\n",
    "    #List of all the available variables\n",
    "    table_variables = df_query(\"SELECT * FROM ReportDataDictionary WHERE ReportingFrequency = 'Hourly'\", sql_dir)\n",
    "\n",
    "    #create empty dataframe\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final.index = pd.date_range(start='2021-01-01 00:00:00', end='2021-12-31 23:59:00', freq='60min')\n",
    "    #Pinpoint individual variable and add it to the results DF\n",
    "    for var in variables:\n",
    "        var_names = filter_tabular(table_variables, var)['KeyValue'].values\n",
    "        indexes = filter_tabular(table_variables, var)['ReportDataDictionaryIndex'].values\n",
    "        for i in range(0,len(indexes)):\n",
    "    #         print(val)\n",
    "            column = df_query('SELECT \"Value\",\"ReportDataDictionaryIndex\",\"TimeIndex\" FROM \"ReportData\" WHERE \"ReportDataDictionaryIndex\"='+ str(indexes[i]), sql_dir)\n",
    "            try:\n",
    "                name = var + '-' + var_names[i]\n",
    "            except TypeError:\n",
    "                name = var\n",
    "            df_final[name] = column['Value']\n",
    "    df_final.to_csv(save_path + simulation_name + '.csv')\n",
    "    \n",
    "# df\n",
    "\n",
    "\n",
    "# listquery = 'SELECT \"Value\",\"ReportDataDictionaryIndex\",\"TimeIndex\" FROM \"ReportData\" WHERE \"ReportDataDictionaryIndex\" IN '+str(tuple(dfidx.ReportDataDictionaryIndex))\n",
    "\n",
    "\n",
    "# # In[2]:\n",
    "\n",
    "# sql_dir = '/Users/cbianchi/Documents/GitHub/example_workflow/output_ERMA/Power_and_Heat_14_Hangar/run/'\n",
    "# sql_file = 'eplusout.sql'\n",
    "# sql_path = os.path.join(sql_dir, sql_file)\n",
    "# print(sql_path)\n",
    "# write_dir = sql_dir\n",
    "\n",
    "# # In[3]:\n",
    "\n",
    "# # Connect an create a cursor\n",
    "# conn = sqlite3.connect(sql_path)\n",
    "\n",
    "# #Create a cursor and return the list of all tables in the database\n",
    "# c = conn.cursor()\n",
    "\n",
    "# # In[4]:\n",
    "\n",
    "# query = \"SELECT * FROM TabularDataWithStrings WHERE TableName='End Uses'\"\n",
    "# query = \"SELECT * FROM ReportDataDictionary WHERE ReportingFrequency = 'Hourly'\"\n",
    "# end_uses = pd.read_sql(query ,conn)\n",
    "# # end_uses.to_csv(os.path.join(write_dir, 'SQL-EndUses.csv'), index=False)\n",
    "# end_uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321b860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5a454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093328fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "epresults_location = '/Users/cbianchi/Documents/GitHub'\n",
    "sys.path.append(epresults_location)\n",
    "\n",
    "import epparse as ep\n",
    "mysim = ep.load.epLoad(sql_dir + 'eplusout.sql')\n",
    "availseries = mysim.sql.availseries() \n",
    "availseries\n",
    "# filtered = availseries[availseries['Name'].str.contains(\"NaturalGas\")]\n",
    "# mydf = mysim.sql.getseries(filtered) # units are 'IP' by default but can be specified as 'SI'\n",
    "# mydf\n",
    "# filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428e8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(availseries['Name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
